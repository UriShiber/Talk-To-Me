"""
this version detects sounds great but letters poorly
"""

import pydub
import numpy as np
import os
import wave
import pyaudio
# import matplotlib.pyplot as plt
from convert_audio_file_to_wave import convert_file_to_wav
from convert_audio_file_to_wave import number_of_files_in_dir
import librosa
import librosa.display
import threading
import queue

RECORDING_DIR = r"C:\Users\Noa\Desktop\uri- final project\Recordings"
FILES_TO_CONVERT_DIR = r"C:\Users\Noa\Desktop\uri- final project\Files to convert"
EXAMPLE_FILE = r"C:\Users\Noa\Desktop\uri- final project\Recordings\record_try_1.wav"
AUDIO_CHUNKS_DIR = r"C:\Users\Noa\Desktop\uri- final project\Recordings\audio_chunks"


def detect_silence(audio_file):
    """
    the len normalizer is in prepare_full_file
    detect spaces.
    first we divide a file to milliseconds - for comfort, we see for each chunk
    if its peak is more than 380 (roughly the volume of speech in these kinds of
    measuring), we write to a new file we open for each word thus (according to
    different kinds of limitations, such as len of silence=100, the norma).
    we get the audio file split to spaces in separate wav files.
    and we get the start and end indexes of a word - for debugging
    letters that are hard to manage (when opening a word):
    """
    wave_file, chunk, stream, p = prepare_full_file(audio_file,
                                                    bool_normalize_duration=False)
    # detects the volume parameter of each record file in order to normalize
    # the audio chunks we get out of it to a 1000 volume
    data = wave_file.readframes(chunk)
    # represents the time of the words ([start, end....]) for debugging
    words_time = []
    not_a_word = []
    num_of_files = 1
    for file in os.listdir(AUDIO_CHUNKS_DIR):
        if os.path.isfile(os.path.join(AUDIO_CHUNKS_DIR, file)):
            num_of_files += 1
    in_a_word = False
    # represents the min len of silence (counts from 0 till 1000)
    times_under_400 = 0
    # represents the milliseconds
    counter = 0
    # if it is the first file i open
    first = True
    # before the loop, the first file must be already declared and opened
    new_wav_file = wave.open(
        r"C:\Users\Noa\Desktop\uri- final project\Recordings\audio_chunks\audio_chunk{0}.wav".format(num_of_files), 'wb')
    new_wav_file.setparams((wave_file.getnchannels(),
                            wave_file.getsampwidth(),
                            wave_file.getframerate(),
                            wave_file.getnframes(),
                            wave_file.getcomptype(),
                            wave_file.getcompname()))
    try:
        # till the end of the file
        while data is not '':
            counter += 1
            # taking the info in chunk of millisecond in np int.16 format
            data = np.fromstring(wave_file.readframes(chunk), dtype=np.int16)
            # calculates a num for a margin of the highest part and lowest parts
            # by taking the absolute value for each member, then
            # calculates the average
            peak = np.average(np.abs(data))
            if not in_a_word:
                if peak > 300:
                    in_a_word = True
                    words_time.append(counter)
                    # if this is the second file, i need to open a new one
                    if not first:
                        num_of_files += 1
                        new_wav_file = wave. \
                            open(
                            r"C:\Users\Noa\Desktop\uri- final project\Recordings\audio_chunks\audio_chunk{0}.wav".
                                format(num_of_files), 'wb')
                        new_wav_file.setparams((wave_file.getnchannels(),
                                                wave_file.getsampwidth(),
                                                wave_file.getframerate(),
                                                wave_file.getnframes(),
                                                wave_file.getcomptype(),
                                                wave_file.getcompname()))
                    # writes the sound to the new file (for each millisecond)
                    # (the start of a new word)
                    new_wav_file.writeframesraw(data)
            if in_a_word:
                # in a word, so write the sound to the new file till you get out
                # of the word
                new_wav_file.writeframesraw(data)
                if peak < 300:
                    times_under_400 += 1
                    if times_under_400 >= 150:  # len of silence
                        in_a_word = False
                        first = False
                        words_time.append(counter)
                        times_under_400 = 0
                        if words_time[-1] - words_time[-2] < 300:
                            not_a_word.append(num_of_files)
                else:
                    times_under_400 = 0
            # for debugging - good indicate for the volume
            # bars = "#" * int(1000 * int(peak) / 2 ** 16)
            int(peak)
            # print("%04d %05d %s" % (counter, peak, bars))
    except ValueError:
        pass
    # stops the stream
    stream.stop_stream()
    stream.close()
    p.terminate()
    if words_time.__len__() % 2 != 0:
        words_time.append(counter)
    if words_time[-1] - words_time[-2] < 300:
        not_a_word.append(num_of_files)
    return words_time.__len__() / 2, not_a_word, words_time


def prepare_full_file(audio_file, bool_normalize_duration):
    """
    a problem with the duration normalizer !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    in order to normalize the duration, needs to be called with a file name and
    true (otherwise calculates regularly):
    600 milliseconds is approximately the duration of a word, as a result i want
    that the duration of all the files will be as if it was 600 so
    each chunk will represent the data of each 1/600 instead of each millisecond
    for example if word's duration is 477, each chunk length will be
    48 (normal proportional chunk size in millisecond) * the duration parameter
    which is duration / 600 which means that every chunk will represent the num
    of frames / 600
    """
    wave_file = wave.open(audio_file, 'rb')
    duration = wave_file.getnframes() / float(wave_file.getframerate())
    duration = duration * 1000
    # the rate of an audio file means the number of updates or chunks in seconds
    # divide that by 1000 and we will get that each chunk will be a millisecond
    # i want that each chunk will be in the size of a millisecond (like in the
    # graph i drew earlier)
    if bool_normalize_duration:
        duration_parameter = duration / 600
        chunk = round(float(wave_file.getframerate() * duration_parameter)
                      / 1000)
    else:
        chunk = round(float(wave_file.getframerate()) / 1000)
    p = pyaudio.PyAudio()
    stream = p.open(format=p.get_format_from_width(wave_file.getsampwidth()),
                    channels=wave_file.getnchannels(),
                    rate=wave_file.getframerate(),
                    output=True)
    return wave_file, chunk, stream, p


def remove_record_garbage(not_a_word, num_of_chunks, words_time):
    """
    deletes the audio chunks that are not words
    :return:
    """
    i = 0
    while i < not_a_word.__len__():
        os.remove(
            r"C:\Users\Noa\Desktop\uri- final project\Recordings\audio_chunks\audio_chunk{0}.wav".
                format(not_a_word[i]))
        del words_time[(not_a_word[i])]
        i += 1
        num_of_chunks -= 1
    print(words_time, not_a_word)
    return num_of_chunks, words_time


def compare_power(signal_power_1, signal_power_2):
    distance = np.linalg.norm(signal_power_1 - signal_power_2)
    return distance


def prepare_return_vowel(vowel, return_string, i, spaces, num_of_chunks):
    """
    need to add shva vowel and the check- if it is the final letter
    :param num_of_chunks:
    :param i:
    :param spaces:
    :param vowel:
    :param return_string:
    :return:
    """
    # the number of new recordings
    num_files = number_of_files_in_dir(AUDIO_CHUNKS_DIR) - 2
    i -= (num_files - num_of_chunks)
    is_final_letter = i in spaces
    if vowel == 'aa':
        if is_final_letter:
            return_string = 'ה'
        else:
            return_string = ''
    elif vowel == 'a':
        if is_final_letter:
            return_string = 'ה'
        else:
            return_string = ''
    elif vowel == 'i':
        return_string = 'י'
    elif vowel == 'o':
        return_string = 'ו'
    elif vowel == 'u':
        return_string = 'ו'
    elif vowel == 'e':
        return_string = ''
    if is_final_letter:
        return_string += ' '
    return return_string


def detect_vowel(my_que, new_example_spec, new_mel_spec, new_end_of_shape,
                 new_relative_index, this_num_of_vowel):
    """
    :param my_que:
    :param this_num_of_vowel:
    :param new_relative_index:
    :param new_end_of_shape:
    :param new_mel_spec:
    :param new_example_spec:
    :return:
    """
    sum_distance = 0
    num_of_folders = 1
    while num_of_folders <= 5:
        path = os.path.join(RECORDING_DIR, "audio_chunks")
        path = os.path.join(path, "vowels{0}".format(num_of_folders))
        example_spec = np.zeros((80, 1200))

        mel_spec = do_mel_spec(os.path.join(path, "audio_chunk{0}.wav".
                                            format(this_num_of_vowel)))
        example_spec[example_spec == 0] = np.min(new_mel_spec)

        start_of_shape, end_of_shape = \
            take_period_of_high_frequency_vowel(mel_spec)
        relative_index = start_of_shape + int(
            (end_of_shape - start_of_shape) / 2)
        mel_spec[:, :] += np.min(new_mel_spec) - np.min(mel_spec)
        try:
            example_spec[:, new_relative_index:new_end_of_shape - 20] = \
                mel_spec[:,
                relative_index:relative_index + new_end_of_shape - new_relative_index - 20]
        except ValueError:
            example_spec[:,
            new_relative_index:new_relative_index + mel_spec.shape[
                1] - relative_index] = mel_spec[:, relative_index:]

        distance = compare_power(example_spec, new_example_spec)
        sum_distance += distance
        num_of_folders += 1

    my_que.put(sum_distance)


def new_vowel(file_name):
    """
    detects the characteristics of the new vowel
    :param file_name:
    :return:
    """
    new_example_spec = np.zeros((80, 1200))
    new_path = os.path.join(RECORDING_DIR, file_name)
    new_mel_spec = do_mel_spec(new_path)
    new_example_spec[new_example_spec == 0] = np.min(new_mel_spec)

    new_start_shape, new_end_of_shape = take_period_of_high_frequency_vowel(
        new_mel_spec)
    new_relative_index = new_start_shape + int(
        (new_end_of_shape - new_start_shape) / 2)

    new_example_spec[:, new_relative_index:new_end_of_shape - 20] = \
        new_mel_spec[:, new_relative_index:new_end_of_shape - 20]
    return new_example_spec, new_mel_spec, new_end_of_shape, new_relative_index


def new_letter(file_name):
    """
        detects the characteristics of the new letter
        :param file_name:
        :return:
        """
    new_example_spec = np.zeros((80, 1200))
    new_path = os.path.join(RECORDING_DIR, file_name)
    new_mel_spec = do_mel_spec(new_path)
    new_example_spec[new_example_spec == 0] = np.min(new_mel_spec)

    new_start_shape, new_end_of_shape = take_period_of_high_frequency_letter(
        new_mel_spec)
    new_relative_index = new_start_shape + int(
        (new_end_of_shape - new_start_shape) / 2)
    # print("new_start_shape:", new_start_shape)
    # if new_start_shape >= 50:
    new_example_spec[:, :new_start_shape + 10] = new_mel_spec[:,
                                                 :new_start_shape + 10]
    # else:
    # there are 2 options:
    # 1) keep the same number of samples (100) each time
    # 2) check until start_of_shape + 50 even if it means different num of samples
    # new_example_spec[:, :150] = new_mel_spec[:, :150]
    # print(new_start_shape)
    return new_example_spec, new_mel_spec, new_end_of_shape, new_relative_index


def detect_letter(my_que, new_example_spec, new_mel_spec, this_num_of_vowel):
    """
    this func is called by the threads it gets the params of the new record,
    sets the params of the old records and compares it to the new one using
    compare_power func
    it actually goes through each letter in the database and compare its average
    to the new vowel, the smaller the margin, the closer the old record is to
    the new record and the closest sum is chosen
    :param my_que: in order to pass the values calculated in the thread,
                   outside of it
    :param new_example_spec: the final 3D numpy array (after taking specified
                             time) of the new record
    :param new_mel_spec: the whole 3D numpy array of the new record
    :param this_num_of_vowel: the number of letter i check
    :return: actually instead of return because this func is called from a
             thread, i put my return value, the sum of distances, in the que, so
             i can reach it later
    """
    sum_distance = 0
    # number of times i recorded each letter
    num_of_folders = 1
    while num_of_folders <= 10:
        # reach for the letters records
        path = os.path.join(RECORDING_DIR, "audio_chunks")
        path = os.path.join(path, "hebrew aaa {0}".format(num_of_folders))
        # get the 3D numpy array of it
        mel_spec = do_mel_spec(
            os.path.join(path, "audio_chunk{0}.wav".format(this_num_of_vowel)))
        example_spec = np.zeros((80, 1200))
        example_spec[example_spec == 0] = np.min(new_mel_spec)
        # get the approximately period of the start of the vowel, end of letter
        start_of_shape, end_of_shape = take_period_of_high_frequency_letter(
            mel_spec)
        # normalizes the arrays so they all have the same range of numbers
        # (the same minimum)
        mel_spec[:, :] += np.min(new_mel_spec) - np.min(mel_spec)
        # take the relevant period and store it in a new array
        example_spec[:, :start_of_shape + 10] = mel_spec[:,
                                                :start_of_shape + 10]
        # compare the final arrays distance from each other
        distance = compare_power(new_example_spec, example_spec)
        # print for debugging and improving
        print(this_num_of_vowel, num_of_folders, int(distance))
        sum_distance += distance
        num_of_folders += 1
    # store in the que
    my_que.put(sum_distance)


def take_period_of_high_frequency_letter(mel_spec):
    """
        :param mel_spec:[0] represents the rows
                        [1] represents the columns
        :return:
        """
    x = np.min(mel_spec)
    i = 0
    j = 0
    firsts = []
    not_first = False
    lasts = [np.shape(mel_spec)[1]]
    time_above_frequency = 0
    while i < np.shape(mel_spec)[1]:
        while j < np.shape(mel_spec)[0]:
            if mel_spec[j, i] > x + 40:
                time_above_frequency += 1
            if time_above_frequency > 10:
                j = np.shape(mel_spec)[0]
            j += 1
        if not_first:
            if time_above_frequency < 10:
                lasts.append(i)
                not_first = False
        if not not_first:
            if time_above_frequency > 10:
                firsts.append(i)
                not_first = True
        j = 0
        i += 1
        time_above_frequency = 0
    # print(firsts[0], lasts[-1])
    if not firsts:
        firsts.append(0)
    return firsts[0], lasts[-1]


def take_period_of_high_frequency_vowel(mel_spec):
    """
    i changed 5 times instead of 10
    :param mel_spec:[0] represents the rows
                    [1] represents the columns
    :return:
    """
    x = np.min(mel_spec)
    i = 0
    j = 0
    firsts = []
    not_first = False
    lasts = [np.shape(mel_spec)[1]]
    time_above_frequency = 0
    while i < np.shape(mel_spec)[1]:
        while j < np.shape(mel_spec)[0]:
            if mel_spec[j, i] > x + 30:
                time_above_frequency += 1
            if time_above_frequency > 5:
                j = np.shape(mel_spec)[0]
            j += 1
        if not_first:
            if time_above_frequency < 5:
                lasts.append(i)
                not_first = False
        if not not_first:
            if time_above_frequency > 5:
                firsts.append(i)
                not_first = True
        j = 0
        i += 1
        time_above_frequency = 0
    # print(firsts[0], lasts[-1])
    return firsts[0], lasts[-1]


def do_mel_spec(audio_path):
    """
    does a mel_spectogram of the given audio file
    actually creates an 3D array that represents the audio signal's power and
    frequency in time
    uses librosa library, librosa.feature.melspectrogram and
    librosa.core.amplitude_to_db which eventually creates the 3D numpy array
    :param audio_path: the audio record that needs to be analyzed
    :return: the 3D numpy array represents the audio's power and frequency
             through time
    """
    # sr = sample rate
    # y = audio time signal (i think amplitude to time) if i take this shape
    # and divide to the sr i get the duration so
    # 4800 values in this will give me each 0.1 second
    # log specto = the power in each frequency and second.
    # in the log_specto if we indices it [:10] it changes the height of each db
    # square so it stretches it over larger
    # amount of frequencies that means that each row in the table represents
    # different frequency and every column represents roughly 0.01 seconds
    [y, sr] = librosa.core.load(audio_path, sr=48000)
    specto = librosa.feature.melspectrogram(y, sr=sr, n_fft=400, hop_length=65,
                                            n_mels=80)
    log_specto = librosa.core.amplitude_to_db(specto)
    return log_specto


def create_threads_for_vowels(num_of_values, file):
    """
    creates threads (no more than 8, computer's ability)
    """
    vowels = ['aa', 'a', 'o', 'u', 'i', 'e']
    total_distances = []
    new_example_spec, new_mel_spec, new_end_of_shape, new_relative_index = new_vowel(
        file)
    my_que = queue.Queue()
    this_num_of_values = 0
    while this_num_of_values < num_of_values:
        if threading.active_count() <= 5:
            this_num_of_values += 1
            th = threading.Thread(target=detect_vowel,
                                  args=(my_que, new_example_spec, new_mel_spec,
                                        new_end_of_shape, new_relative_index,
                                        this_num_of_values))
            th.start()
            result = my_que.get()
            total_distances.append(result)
    print(total_distances)
    total_distances[3] += 1000
    if any(total_distances) == 0:
        return vowels[5]
    return vowels[total_distances.index(min(total_distances))]


def create_threads_for_letters(num_of_values, file):
    """
    creates threads (no more than 8, computer's ability)
    """
    letters = ['א', 'ב', 'ג', 'ד', 'ה', 'ו', 'ז', 'ח', 'ט', 'י', 'כ', 'ל', 'מ',
               'נ', 'ס', 'ע', 'פ', 'צ', 'ק', 'ר', 'ש',
               'ת', 'פ']
    total_distances = []
    new_example_spec, new_mel_spec, new_end_of_shape, new_relative_index = new_letter(
        file)
    my_que = queue.Queue()
    this_num_of_values = 0
    while this_num_of_values < num_of_values:
        if threading.active_count() <= 1:
            # print(this_num_of_values)
            this_num_of_values += 1
            th = threading.Thread(target=detect_letter,
                                  args=(my_que, new_example_spec, new_mel_spec,
                                        this_num_of_values))
            th.start()
            if this_num_of_values >= num_of_values:
                break
        result = my_que.get()
        total_distances.append(result)
    result = my_que.get()
    total_distances.append(result)
    for i in range(total_distances.__len__()):
        print(i + 1, int(total_distances[i]))
    return letters[total_distances.index(min(total_distances))]


def detect_spaces_between_words(words_time):
    """
    detects the indexes of the syllables that are in the end of a word
    :param words_time:
    :return:
    """
    spaces = []
    for i in range(words_time.__len__()):
        if i % 2 == 1 and i + 1 < words_time.__len__():
            if words_time[i + 1] - words_time[i] > 1000:
                spaces.append((i + 1) / 2)
        elif i + 1 >= words_time.__len__():
            spaces.append((i + 1) / 2)
    return spaces


def main_analyzer(counter):
    """
    in detecting the word i will need to see first if the file exist because i
    am deleting some that are not good
    =======================================================
    in the future i will make each vowel a process so i can analyze 5 vowels at
    a time and that the time to develop 4 vowels will be like 1- 7.5s (only if
    connected to the electricity - on the laptop)
    :return: the return_string- the ultimate result, the meaning of the record
             in hebrew writing
    """
    try:
        # creating a wav file from a recording -------------------------------------
        audio_file = convert_file_to_wav(os.path.join(FILES_TO_CONVERT_DIR,
                                                      "my_record{0}".
                                                      format(counter)))
        # separating the audio into words ------------------------------------------
        i = number_of_files_in_dir(AUDIO_CHUNKS_DIR) - 1
        num_of_chunks, not_a_word, words_time = detect_silence(audio_file)
        num_of_vowels, words_time = remove_record_garbage(not_a_word,
                                                          num_of_chunks,
                                                          words_time)
        spaces = detect_spaces_between_words(words_time)
        # detecting the letter and the vowel ---------------------------------------
        return_string = ""
        num_of_chunks = num_of_vowels
        num_of_vowels += i - 1

        # going through each syllable and detecting its vowel and letter
        while i <= num_of_vowels:
            # getting the name of the file
            file = os.path.join(AUDIO_CHUNKS_DIR,
                                "audio_chunk{0}.wav".format(i))
            # file = os.path.join(r"C:\Users\Noa\Desktop\uri- final project\
            # Recordings\audio_chunks", "audio_chunk2.wav")
            # detecting the letter
            return_string += create_threads_for_letters(23, file)
            # detecting the vowel
            vowel = create_threads_for_vowels(6, file)
            return_string += prepare_return_vowel(vowel, return_string, i,
                                                  spaces, num_of_chunks)
            i += 1
        # ----------------------------------------------------------------------
        print(return_string)
        return return_string
    except ValueError:
        return "server err"
    except pydub.audio_segment.CouldntDecodeError:
        return "please record again"
    except FileNotFoundError:
        return "server err"


if __name__ == '__main__':
    main_analyzer(1)
